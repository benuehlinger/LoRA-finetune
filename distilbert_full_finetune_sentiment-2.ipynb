{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets huggingface_hub --upgrade peft"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-07-22T23:04:11.343507Z",
          "iopub.execute_input": "2024-07-22T23:04:11.344413Z",
          "iopub.status.idle": "2024-07-22T23:04:37.421702Z",
          "shell.execute_reply.started": "2024-07-22T23:04:11.344381Z",
          "shell.execute_reply": "2024-07-22T23:04:37.420799Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "mPs39Q3pokgd",
        "outputId": "ec8f59df-eb05-4619-9586-32e1defaa862"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\nCollecting transformers\n  Downloading transformers-4.42.4-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.20.0)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.23.4)\nCollecting huggingface_hub\n  Downloading huggingface_hub-0.24.0-py3-none-any.whl.metadata (13 kB)\nCollecting peft\n  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.9.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.32.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading transformers-4.42.4-py3-none-any.whl (9.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.24.0-py3-none-any.whl (419 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m419.0/419.0 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: huggingface_hub, transformers, peft\n  Attempting uninstall: huggingface_hub\n    Found existing installation: huggingface-hub 0.23.4\n    Uninstalling huggingface-hub-0.23.4:\n      Successfully uninstalled huggingface-hub-0.23.4\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.42.3\n    Uninstalling transformers-4.42.3:\n      Successfully uninstalled transformers-4.42.3\nSuccessfully installed huggingface_hub-0.24.0 peft-0.11.1 transformers-4.42.4\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to distilbert-base-uncased from huggingface"
      ],
      "metadata": {
        "id": "Wob_ubefokge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
        "# Import required libraries\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast, Trainer, TrainingArguments, pipeline\n",
        "from datasets import load_dataset, load_metric\n",
        "\n",
        "\n",
        "# Load the pre-trained model and tokenizer\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T23:04:46.298237Z",
          "iopub.execute_input": "2024-07-22T23:04:46.298832Z",
          "iopub.status.idle": "2024-07-22T23:05:09.668801Z",
          "shell.execute_reply.started": "2024-07-22T23:04:46.298791Z",
          "shell.execute_reply": "2024-07-22T23:05:09.668041Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "032118c00a6d4fc5aef8d5c4edbb4782",
            "583dfcd6a510403a9466a0a77d2e2698",
            "711ebfc8fa60455da2506845c699664a",
            "83e1266f386f4872928eaa4e22cd41f6",
            "a3e7379c156b44f8bb19d695b92163e5"
          ]
        },
        "id": "EIUhsgRJokgg",
        "outputId": "24a509a2-4e54-45a3-e18c-69cd8819f8d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2024-07-22 23:04:53.485844: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-22 23:04:53.485971: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-22 23:04:53.635004: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "032118c00a6d4fc5aef8d5c4edbb4782"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "583dfcd6a510403a9466a0a77d2e2698"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "711ebfc8fa60455da2506845c699664a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83e1266f386f4872928eaa4e22cd41f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3e7379c156b44f8bb19d695b92163e5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find and Load SST-2 Dataset from Hugging Face to fine tune model"
      ],
      "metadata": {
        "id": "YmENAMZdokgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "# Load the SST-2 dataset\n",
        "dataset = load_dataset('glue', 'sst2') #The sst2 (Stanford Sentiment Treebank 2) is one of the datasets within the GLUE benchmark. SST-2 specifically focuses on sentiment analysis, providing sentences labeled as either positive or negative\n",
        "\n",
        "\n",
        "\n",
        "# Convert samples to DataFrames for better formatting\n",
        "train_samples = pd.DataFrame(dataset['train'][:5])  # First 5 entries from the training set\n",
        "validation_samples = pd.DataFrame(dataset['validation'][:5])  # First 5 entries from the validation set\n",
        "\n",
        "# Function to display DataFrame as a well-formatted table\n",
        "def display_table(title, df):\n",
        "    print(f\"\\n{title}\")\n",
        "    print(tabulate(df, headers='keys', tablefmt='pretty', showindex=False))\n",
        "\n",
        "# Display the sample entries as well-formatted tables with titles\n",
        "display_table(\"Sample entries from the SST-2 training dataset:\", train_samples)\n",
        "display_table(\"Sample entries from the SST-2 validation dataset:\", validation_samples)\n",
        "\n",
        "\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['sentence'], truncation=True, padding=True)\n",
        "\n",
        "encoded_dataset = dataset.map(tokenize_function, batched=True)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T23:05:13.935337Z",
          "iopub.execute_input": "2024-07-22T23:05:13.936006Z",
          "iopub.status.idle": "2024-07-22T23:05:24.156939Z",
          "shell.execute_reply.started": "2024-07-22T23:05:13.935973Z",
          "shell.execute_reply": "2024-07-22T23:05:24.156065Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "920fb9a7c6e94b9e8f16f0823be2f6f8",
            "e83fe7bdb8ec441794d236d0742e4788",
            "7011da658ba648a3872dffce1f545cbd",
            "c2462fb1e9d1493d99744b690ca467a6",
            "05ec69e05d0041b8a2e07ae623aa739e",
            "5ac9ec96c3b44ccb92a7b384614e5820",
            "e545e15d344f488ba10fb8fdcdf2fc82",
            "fd7cbbc40ffc43429efdd366340f2571",
            "4da27f55f7bc440baaf96b0d4843a79c",
            "544a786e579d46be9fbcf1309f8ce1b2"
          ]
        },
        "id": "A_Gxpznlokgh",
        "outputId": "28b9786a-1540-4208-9974-75ef1f05e22c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading readme:   0%|          | 0.00/35.3k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "920fb9a7c6e94b9e8f16f0823be2f6f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/3.11M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e83fe7bdb8ec441794d236d0742e4788"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/72.8k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7011da658ba648a3872dffce1f545cbd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/148k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2462fb1e9d1493d99744b690ca467a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05ec69e05d0041b8a2e07ae623aa739e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ac9ec96c3b44ccb92a7b384614e5820"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e545e15d344f488ba10fb8fdcdf2fc82"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\nSample entries from the SST-2 training dataset:\n+------------------------------------------------------------------------------------------+-------+-----+\n|                                         sentence                                         | label | idx |\n+------------------------------------------------------------------------------------------+-------+-----+\n|                       hide new secretions from the parental units                        |   0   |  0  |\n|                           contains no wit , only labored gags                            |   0   |  1  |\n| that loves its characters and communicates something rather beautiful about human nature |   1   |  2  |\n|                 remains utterly satisfied to remain the same throughout                  |   0   |  3  |\n|         on the worst revenge-of-the-nerds clichÃ©s the filmmakers could dredge up         |   0   |  4  |\n+------------------------------------------------------------------------------------------+-------+-----+\n\nSample entries from the SST-2 validation dataset:\n+-----------------------------------------------------------------------------------------------------------------------+-------+-----+\n|                                                       sentence                                                        | label | idx |\n+-----------------------------------------------------------------------------------------------------------------------+-------+-----+\n|                                    it 's a charming and often affecting journey .                                     |   1   |  0  |\n|                                           unflinchingly bleak and desperate                                           |   0   |  1  |\n|       allows us to hope that nolan is poised to embark a major career as a commercial yet inventive filmmaker .       |   1   |  2  |\n| the acting , costumes , music , cinematography and sound are all astounding given the production 's austere locales . |   1   |  3  |\n|                                           it 's slow -- very , very slow .                                            |   0   |  4  |\n+-----------------------------------------------------------------------------------------------------------------------+-------+-----+\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd7cbbc40ffc43429efdd366340f2571"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/872 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4da27f55f7bc440baaf96b0d4843a79c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/1821 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "544a786e579d46be9fbcf1309f8ce1b2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to Hugging Face"
      ],
      "metadata": {
        "id": "csrRxO_fokgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T23:05:29.492494Z",
          "iopub.execute_input": "2024-07-22T23:05:29.493343Z",
          "iopub.status.idle": "2024-07-22T23:05:29.516328Z",
          "shell.execute_reply.started": "2024-07-22T23:05:29.493313Z",
          "shell.execute_reply": "2024-07-22T23:05:29.515492Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "c25454c1c13e4ee4855b7dee4871072e"
          ]
        },
        "id": "4DUG9C8Wokgi",
        "outputId": "b3cb5a0c-a170-4ba5-f504-17124848ba60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c25454c1c13e4ee4855b7dee4871072e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check if connected"
      ],
      "metadata": {
        "id": "V7rzxdEVokgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# URL to test (Hugging Face's model hub)\n",
        "url_to_test = \"https://huggingface.co\"\n",
        "\n",
        "try:\n",
        "    # Send a GET request to the URL\n",
        "    response = requests.get(url_to_test)\n",
        "\n",
        "    # Check if the request was successful (status code 200)\n",
        "    if response.status_code == 200:\n",
        "        print(\"Connected to Hugging Face's model hub.\")\n",
        "    else:\n",
        "        print(\"Not connected to Hugging Face's model hub.\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Connection error: {e}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-22T23:05:55.811284Z",
          "iopub.execute_input": "2024-07-22T23:05:55.811678Z",
          "iopub.status.idle": "2024-07-22T23:05:55.849310Z",
          "shell.execute_reply.started": "2024-07-22T23:05:55.811647Z",
          "shell.execute_reply": "2024-07-22T23:05:55.848404Z"
        },
        "trusted": true,
        "id": "w9y9gC98okgi",
        "outputId": "8fba5a27-fb2c-4a19-85ba-4d6e312158f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Connected to Hugging Face's model hub.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run full fine tune, commit to Hugging Face (DO NOT RE RUN)"
      ],
      "metadata": {
        "id": "p1jUfQHmokgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import load_metric\n",
        "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from huggingface_hub import HfApi, HfFolder\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load the accuracy metric\n",
        "metric = load_metric('accuracy')\n",
        "\n",
        "# Define the compute_metrics function\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = predictions.argmax(axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results', # Directory to save the model and checkpoints\n",
        "    evaluation_strategy='epoch',# Evaluate the model at the end of each epoch\n",
        "    save_strategy='epoch', # Save the model at the end of each epoch\n",
        "    learning_rate=2e-5,# Learning rate for the optimizer\n",
        "    per_device_train_batch_size=16, # Batch size for training on each device\n",
        "    per_device_eval_batch_size=16,  # Batch size for evaluation on each device\n",
        "    num_train_epochs=3, # Number of epochs to train the model\n",
        "    weight_decay=0.01, # Weight decay to apply for regularization\n",
        "    logging_dir='./logs', # Directory to save the logs\n",
        "    logging_steps=10, # Log training information every 10 steps\n",
        "    push_to_hub=True  # Enable pushing to hugging face\n",
        ")\n",
        "\n",
        "# Load the model and move it to the appropriate device\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
        "model.to(device)\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_dataset['train'],\n",
        "    eval_dataset=encoded_dataset['validation'],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Evaluate before fine-tuning\n",
        "print(\"Evaluating before fine-tuning...\")\n",
        "pre_finetune_results = trainer.evaluate()\n",
        "print(\"Results before fine-tuning:\", pre_finetune_results)\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate after fine-tuning\n",
        "print(\"Evaluating after fine-tuning...\")\n",
        "post_finetune_results = trainer.evaluate()\n",
        "print(\"Results after fine-tuning:\", post_finetune_results)\n",
        "\n",
        "# Save the model and tokenizer locally\n",
        "model.save_pretrained('./fine-tuned-model')\n",
        "tokenizer.save_pretrained('./fine-tuned-tokenizer')\n",
        "\n",
        "# Push the model and tokenizer to Hugging Face's Model Hub\n",
        "model.push_to_hub(\"my-fine-tuned-distilbert\")\n",
        "tokenizer.push_to_hub(\"my-fine-tuned-distilbert\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-12T21:24:20.990252Z",
          "iopub.execute_input": "2024-06-12T21:24:20.990707Z",
          "iopub.status.idle": "2024-06-12T21:42:30.434581Z",
          "shell.execute_reply.started": "2024-06-12T21:24:20.990667Z",
          "shell.execute_reply": "2024-06-12T21:42:30.433483Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "b1661ca6685c4fac91602752e880f4bf",
            "a55808d28e8143c9a5e29c3fd2ecdf39"
          ]
        },
        "id": "bOqkPmQPokgj",
        "outputId": "0629c10a-8f3f-474a-a5fa-4fbe0bce6a30"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Using device: cuda\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.2/metrics/accuracy/accuracy.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Evaluating before fine-tuning...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='56' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [28/28 06:12]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:",
          "output_type": "stream"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "wandb version 0.17.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.17.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20240612_212437-ld8bqoqx</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/benuehlinger2/huggingface/runs/ld8bqoqx' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/benuehlinger2/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/benuehlinger2/huggingface' target=\"_blank\">https://wandb.ai/benuehlinger2/huggingface</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/benuehlinger2/huggingface/runs/ld8bqoqx' target=\"_blank\">https://wandb.ai/benuehlinger2/huggingface/runs/ld8bqoqx</a>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Results before fine-tuning: {'eval_loss': 0.6972277760505676, 'eval_accuracy': 0.43463302752293576, 'eval_runtime': 4.4464, 'eval_samples_per_second': 196.112, 'eval_steps_per_second': 6.297}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6315/6315 17:15, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.213100</td>\n      <td>0.271784</td>\n      <td>0.905963</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.161600</td>\n      <td>0.352769</td>\n      <td>0.889908</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.098100</td>\n      <td>0.360013</td>\n      <td>0.903670</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Evaluating after fine-tuning...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [28/28 00:01]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Results after fine-tuning: {'eval_loss': 0.3600134253501892, 'eval_accuracy': 0.9036697247706422, 'eval_runtime': 1.5224, 'eval_samples_per_second': 572.768, 'eval_steps_per_second': 18.392, 'epoch': 3.0}\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1661ca6685c4fac91602752e880f4bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a55808d28e8143c9a5e29c3fd2ecdf39"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "CommitInfo(commit_url='https://huggingface.co/Benuehlinger/my-fine-tuned-distilbert/commit/23bdb76ee908593a411656a40b3441909162c5a9', commit_message='Upload tokenizer', commit_description='', oid='23bdb76ee908593a411656a40b3441909162c5a9', pr_url=None, pr_revision=None, pr_num=None)"
          },
          "metadata": {}
        }
      ]
    }
  ]
}