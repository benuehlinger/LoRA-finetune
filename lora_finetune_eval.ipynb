{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30746,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install peft==0.4.0 datasets"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-30T15:13:28.542475Z",
          "iopub.execute_input": "2024-07-30T15:13:28.542840Z",
          "iopub.status.idle": "2024-07-30T15:13:42.436803Z",
          "shell.execute_reply.started": "2024-07-30T15:13:28.542810Z",
          "shell.execute_reply": "2024-07-30T15:13:42.435793Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "rFMeFiHEuZpM",
        "outputId": "fcdd3767-bf1d-410f-a6d1-7cb54d1f7e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Collecting peft==0.4.0\n  Downloading peft-0.4.0-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.20.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (4.42.3)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (0.32.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (0.4.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.4.0) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.4.0) (2023.12.25)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.4.0) (0.19.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.4.0) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.4.0) (1.3.0)\nDownloading peft-0.4.0-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.4.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Take a look at the possible modules\n",
        ""
      ],
      "metadata": {
        "id": "33JinEqluZpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "def print_modules(model, indent=0):\n",
        "    for name, module in model.named_children():\n",
        "        print('  ' * indent + f\"└─ {name}: {type(module).__name__}\")\n",
        "        if list(module.children()):\n",
        "            print_modules(module, indent + 1)\n",
        "        else:\n",
        "            for param_name, param in module.named_parameters(recurse=False):\n",
        "                print('  ' * (indent + 1) + f\"└─ {param_name}: {param.shape}\")\n",
        "\n",
        "# Load the model\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
        "\n",
        "# Print all modules\n",
        "print(\"All modules in DistilBERT:\")\n",
        "print_modules(model)\n",
        "\n",
        "# Print all module names in a flat list\n",
        "print(\"\\nAll module names (flat list):\")\n",
        "for name, _ in model.named_modules():\n",
        "    print(name)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-30T15:54:48.823217Z",
          "iopub.execute_input": "2024-07-30T15:54:48.824071Z",
          "iopub.status.idle": "2024-07-30T15:54:49.283919Z",
          "shell.execute_reply.started": "2024-07-30T15:54:48.824029Z",
          "shell.execute_reply": "2024-07-30T15:54:49.282941Z"
        },
        "trusted": true,
        "id": "Lo6vXkrCuZpQ",
        "outputId": "62528d0c-8ce8-41bc-a108-89b3b70ecefe"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "All modules in DistilBERT:\n└─ distilbert: DistilBertModel\n  └─ embeddings: Embeddings\n    └─ word_embeddings: Embedding\n      └─ weight: torch.Size([30522, 768])\n    └─ position_embeddings: Embedding\n      └─ weight: torch.Size([512, 768])\n    └─ LayerNorm: LayerNorm\n      └─ weight: torch.Size([768])\n      └─ bias: torch.Size([768])\n    └─ dropout: Dropout\n  └─ transformer: Transformer\n    └─ layer: ModuleList\n      └─ 0: TransformerBlock\n        └─ attention: MultiHeadSelfAttention\n          └─ dropout: Dropout\n          └─ q_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n          └─ k_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n          └─ v_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n          └─ out_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n        └─ sa_layer_norm: LayerNorm\n          └─ weight: torch.Size([768])\n          └─ bias: torch.Size([768])\n        └─ ffn: FFN\n          └─ dropout: Dropout\n          └─ lin1: Linear\n            └─ weight: torch.Size([3072, 768])\n            └─ bias: torch.Size([3072])\n          └─ lin2: Linear\n            └─ weight: torch.Size([768, 3072])\n            └─ bias: torch.Size([768])\n          └─ activation: GELUActivation\n        └─ output_layer_norm: LayerNorm\n          └─ weight: torch.Size([768])\n          └─ bias: torch.Size([768])\n      └─ 1: TransformerBlock\n        └─ attention: MultiHeadSelfAttention\n          └─ dropout: Dropout\n          └─ q_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n          └─ k_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n          └─ v_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n          └─ out_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n        └─ sa_layer_norm: LayerNorm\n          └─ weight: torch.Size([768])\n          └─ bias: torch.Size([768])\n        └─ ffn: FFN\n          └─ dropout: Dropout\n          └─ lin1: Linear\n            └─ weight: torch.Size([3072, 768])\n            └─ bias: torch.Size([3072])\n          └─ lin2: Linear\n            └─ weight: torch.Size([768, 3072])\n            └─ bias: torch.Size([768])\n          └─ activation: GELUActivation\n        └─ output_layer_norm: LayerNorm\n          └─ weight: torch.Size([768])\n          └─ bias: torch.Size([768])\n      └─ 2: TransformerBlock\n        └─ attention: MultiHeadSelfAttention\n          └─ dropout: Dropout\n          └─ q_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n          └─ k_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n          └─ v_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n          └─ out_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n        └─ sa_layer_norm: LayerNorm\n          └─ weight: torch.Size([768])\n          └─ bias: torch.Size([768])\n        └─ ffn: FFN\n          └─ dropout: Dropout\n          └─ lin1: Linear\n            └─ weight: torch.Size([3072, 768])\n            └─ bias: torch.Size([3072])\n          └─ lin2: Linear\n            └─ weight: torch.Size([768, 3072])\n            └─ bias: torch.Size([768])\n          └─ activation: GELUActivation\n        └─ output_layer_norm: LayerNorm\n          └─ weight: torch.Size([768])\n          └─ bias: torch.Size([768])\n      └─ 3: TransformerBlock\n        └─ attention: MultiHeadSelfAttention\n          └─ dropout: Dropout\n          └─ q_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n          └─ k_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n          └─ v_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n          └─ out_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n        └─ sa_layer_norm: LayerNorm\n          └─ weight: torch.Size([768])\n          └─ bias: torch.Size([768])\n        └─ ffn: FFN\n          └─ dropout: Dropout\n          └─ lin1: Linear\n            └─ weight: torch.Size([3072, 768])\n            └─ bias: torch.Size([3072])\n          └─ lin2: Linear\n            └─ weight: torch.Size([768, 3072])\n            └─ bias: torch.Size([768])\n          └─ activation: GELUActivation\n        └─ output_layer_norm: LayerNorm\n          └─ weight: torch.Size([768])\n          └─ bias: torch.Size([768])\n      └─ 4: TransformerBlock\n        └─ attention: MultiHeadSelfAttention\n          └─ dropout: Dropout\n          └─ q_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n          └─ k_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n          └─ v_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n          └─ out_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n        └─ sa_layer_norm: LayerNorm\n          └─ weight: torch.Size([768])\n          └─ bias: torch.Size([768])\n        └─ ffn: FFN\n          └─ dropout: Dropout\n          └─ lin1: Linear\n            └─ weight: torch.Size([3072, 768])\n            └─ bias: torch.Size([3072])\n          └─ lin2: Linear\n            └─ weight: torch.Size([768, 3072])\n            └─ bias: torch.Size([768])\n          └─ activation: GELUActivation\n        └─ output_layer_norm: LayerNorm\n          └─ weight: torch.Size([768])\n          └─ bias: torch.Size([768])\n      └─ 5: TransformerBlock\n        └─ attention: MultiHeadSelfAttention\n          └─ dropout: Dropout\n          └─ q_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n          └─ k_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n          └─ v_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n          └─ out_lin: Linear\n            └─ weight: torch.Size([768, 768])\n            └─ bias: torch.Size([768])\n        └─ sa_layer_norm: LayerNorm\n          └─ weight: torch.Size([768])\n          └─ bias: torch.Size([768])\n        └─ ffn: FFN\n          └─ dropout: Dropout\n          └─ lin1: Linear\n            └─ weight: torch.Size([3072, 768])\n            └─ bias: torch.Size([3072])\n          └─ lin2: Linear\n            └─ weight: torch.Size([768, 3072])\n            └─ bias: torch.Size([768])\n          └─ activation: GELUActivation\n        └─ output_layer_norm: LayerNorm\n          └─ weight: torch.Size([768])\n          └─ bias: torch.Size([768])\n└─ pre_classifier: Linear\n  └─ weight: torch.Size([768, 768])\n  └─ bias: torch.Size([768])\n└─ classifier: Linear\n  └─ weight: torch.Size([2, 768])\n  └─ bias: torch.Size([2])\n└─ dropout: Dropout\n\nAll module names (flat list):\n\ndistilbert\ndistilbert.embeddings\ndistilbert.embeddings.word_embeddings\ndistilbert.embeddings.position_embeddings\ndistilbert.embeddings.LayerNorm\ndistilbert.embeddings.dropout\ndistilbert.transformer\ndistilbert.transformer.layer\ndistilbert.transformer.layer.0\ndistilbert.transformer.layer.0.attention\ndistilbert.transformer.layer.0.attention.dropout\ndistilbert.transformer.layer.0.attention.q_lin\ndistilbert.transformer.layer.0.attention.k_lin\ndistilbert.transformer.layer.0.attention.v_lin\ndistilbert.transformer.layer.0.attention.out_lin\ndistilbert.transformer.layer.0.sa_layer_norm\ndistilbert.transformer.layer.0.ffn\ndistilbert.transformer.layer.0.ffn.dropout\ndistilbert.transformer.layer.0.ffn.lin1\ndistilbert.transformer.layer.0.ffn.lin2\ndistilbert.transformer.layer.0.ffn.activation\ndistilbert.transformer.layer.0.output_layer_norm\ndistilbert.transformer.layer.1\ndistilbert.transformer.layer.1.attention\ndistilbert.transformer.layer.1.attention.dropout\ndistilbert.transformer.layer.1.attention.q_lin\ndistilbert.transformer.layer.1.attention.k_lin\ndistilbert.transformer.layer.1.attention.v_lin\ndistilbert.transformer.layer.1.attention.out_lin\ndistilbert.transformer.layer.1.sa_layer_norm\ndistilbert.transformer.layer.1.ffn\ndistilbert.transformer.layer.1.ffn.dropout\ndistilbert.transformer.layer.1.ffn.lin1\ndistilbert.transformer.layer.1.ffn.lin2\ndistilbert.transformer.layer.1.ffn.activation\ndistilbert.transformer.layer.1.output_layer_norm\ndistilbert.transformer.layer.2\ndistilbert.transformer.layer.2.attention\ndistilbert.transformer.layer.2.attention.dropout\ndistilbert.transformer.layer.2.attention.q_lin\ndistilbert.transformer.layer.2.attention.k_lin\ndistilbert.transformer.layer.2.attention.v_lin\ndistilbert.transformer.layer.2.attention.out_lin\ndistilbert.transformer.layer.2.sa_layer_norm\ndistilbert.transformer.layer.2.ffn\ndistilbert.transformer.layer.2.ffn.dropout\ndistilbert.transformer.layer.2.ffn.lin1\ndistilbert.transformer.layer.2.ffn.lin2\ndistilbert.transformer.layer.2.ffn.activation\ndistilbert.transformer.layer.2.output_layer_norm\ndistilbert.transformer.layer.3\ndistilbert.transformer.layer.3.attention\ndistilbert.transformer.layer.3.attention.dropout\ndistilbert.transformer.layer.3.attention.q_lin\ndistilbert.transformer.layer.3.attention.k_lin\ndistilbert.transformer.layer.3.attention.v_lin\ndistilbert.transformer.layer.3.attention.out_lin\ndistilbert.transformer.layer.3.sa_layer_norm\ndistilbert.transformer.layer.3.ffn\ndistilbert.transformer.layer.3.ffn.dropout\ndistilbert.transformer.layer.3.ffn.lin1\ndistilbert.transformer.layer.3.ffn.lin2\ndistilbert.transformer.layer.3.ffn.activation\ndistilbert.transformer.layer.3.output_layer_norm\ndistilbert.transformer.layer.4\ndistilbert.transformer.layer.4.attention\ndistilbert.transformer.layer.4.attention.dropout\ndistilbert.transformer.layer.4.attention.q_lin\ndistilbert.transformer.layer.4.attention.k_lin\ndistilbert.transformer.layer.4.attention.v_lin\ndistilbert.transformer.layer.4.attention.out_lin\ndistilbert.transformer.layer.4.sa_layer_norm\ndistilbert.transformer.layer.4.ffn\ndistilbert.transformer.layer.4.ffn.dropout\ndistilbert.transformer.layer.4.ffn.lin1\ndistilbert.transformer.layer.4.ffn.lin2\ndistilbert.transformer.layer.4.ffn.activation\ndistilbert.transformer.layer.4.output_layer_norm\ndistilbert.transformer.layer.5\ndistilbert.transformer.layer.5.attention\ndistilbert.transformer.layer.5.attention.dropout\ndistilbert.transformer.layer.5.attention.q_lin\ndistilbert.transformer.layer.5.attention.k_lin\ndistilbert.transformer.layer.5.attention.v_lin\ndistilbert.transformer.layer.5.attention.out_lin\ndistilbert.transformer.layer.5.sa_layer_norm\ndistilbert.transformer.layer.5.ffn\ndistilbert.transformer.layer.5.ffn.dropout\ndistilbert.transformer.layer.5.ffn.lin1\ndistilbert.transformer.layer.5.ffn.lin2\ndistilbert.transformer.layer.5.ffn.activation\ndistilbert.transformer.layer.5.output_layer_norm\npre_classifier\nclassifier\ndropout\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine tune the model using LoRA and commit to Hugging Face"
      ],
      "metadata": {
        "id": "MJXV4tNfuheR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import load_dataset, load_metric\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast, Trainer, TrainingArguments\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "from huggingface_hub import HfApi, HfFolder\n",
        "from getpass import getpass\n",
        "\n",
        "# Prompt for Hugging Face access token\n",
        "hf_token = getpass(\"Enter your Hugging Face access token: \")\n",
        "\n",
        "# Set up GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load dataset and tokenizer\n",
        "dataset = load_dataset('glue', 'sst2')\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['sentence'], truncation=True, padding=True)\n",
        "\n",
        "encoded_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Load the accuracy metric\n",
        "metric = load_metric('accuracy')\n",
        "\n",
        "# Define the compute_metrics function\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = predictions.argmax(axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# Set up training arguments for GPU\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    push_to_hub=True,\n",
        "    hub_token=hf_token,\n",
        "    fp16=True  # Enable mixed precision training\n",
        ")\n",
        "\n",
        "# Load the model\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
        "\n",
        "# Print model architecture\n",
        "print(model)\n",
        "\n",
        "# Identify potential target modules\n",
        "target_modules = [name for name, module in model.named_modules() if \"lin\" in name]\n",
        "print(\"Potential target modules:\", target_modules)\n",
        "\n",
        "# Define LoRA Config\n",
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    target_modules=target_modules\n",
        ")\n",
        "\n",
        "# Get the PEFT model and move to GPU\n",
        "peft_model = get_peft_model(model, peft_config)\n",
        "peft_model.to(device)\n",
        "peft_model.print_trainable_parameters()\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_dataset['train'],\n",
        "    eval_dataset=encoded_dataset['validation'],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate after fine-tuning\n",
        "print(\"Evaluating after fine-tuning...\")\n",
        "post_finetune_results = trainer.evaluate()\n",
        "print(\"Results after fine-tuning:\", post_finetune_results)\n",
        "\n",
        "# Save the PEFT model locally\n",
        "peft_model.save_pretrained('./peft-model')\n",
        "\n",
        "# Push the PEFT model to Hugging Face's Model Hub\n",
        "peft_model.push_to_hub(\"my-peft-distilbert\", use_auth_token=hf_token)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-30T15:13:52.003233Z",
          "iopub.execute_input": "2024-07-30T15:13:52.003627Z",
          "iopub.status.idle": "2024-07-30T15:30:45.972057Z",
          "shell.execute_reply.started": "2024-07-30T15:13:52.003594Z",
          "shell.execute_reply": "2024-07-30T15:30:45.969935Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "7e841e34797c47cba7a59cb5eead55ab",
            "fc78134c6fd94c5b90601492a3b0d17f",
            "e8f1ff7e96f840ecbe59dbc61dce12a2",
            "762158df435741bbbbd7a9df39f5fe05",
            "36b5310f7a5a4c38938670530ad88b18",
            "c7be04171f8642a89e5dacbb15c576b7",
            "b116f81214794953a558a4b109947c8d",
            "3ed7456c85d345049a288c750ac0f403",
            "d069e4f178c445f0881587fc7a66e871",
            "a3c3ffab2952435fbadd5c858a4141cb",
            "ac7757d504b841719ac06d991fc81a45",
            "1ac6179967dc4bf5a983fc73c744f7fb",
            "90b53b75cddc44478180cff50ba019c3",
            "7a9ee56c06d541ef84fd489c016251ea",
            "3b15564a4c6c4fc18fb0aba8bdb09b86",
            "d458d46c91ac4701ac874da26d13c8d9",
            "3e99fa74517a49eaaccc24f10e664a9a"
          ]
        },
        "id": "TODZKZVEuZpR",
        "outputId": "81ebdefb-80ba-405a-94b7-eb56ec474395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "Enter your Hugging Face access token:  ·····································\n"
        },
        {
          "name": "stdout",
          "text": "Using device: cuda\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading readme:   0%|          | 0.00/35.3k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e841e34797c47cba7a59cb5eead55ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/3.11M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc78134c6fd94c5b90601492a3b0d17f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/72.8k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8f1ff7e96f840ecbe59dbc61dce12a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/148k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "762158df435741bbbbd7a9df39f5fe05"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36b5310f7a5a4c38938670530ad88b18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7be04171f8642a89e5dacbb15c576b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b116f81214794953a558a4b109947c8d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ed7456c85d345049a288c750ac0f403"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d069e4f178c445f0881587fc7a66e871"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3c3ffab2952435fbadd5c858a4141cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac7757d504b841719ac06d991fc81a45"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ac6179967dc4bf5a983fc73c744f7fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/872 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90b53b75cddc44478180cff50ba019c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/1821 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a9ee56c06d541ef84fd489c016251ea"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_34/3367601975.py:26: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n  metric = load_metric('accuracy')\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b15564a4c6c4fc18fb0aba8bdb09b86"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "The repository for accuracy contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/accuracy.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d458d46c91ac4701ac874da26d13c8d9"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)\nPotential target modules: ['distilbert.transformer.layer.0.attention.q_lin', 'distilbert.transformer.layer.0.attention.k_lin', 'distilbert.transformer.layer.0.attention.v_lin', 'distilbert.transformer.layer.0.attention.out_lin', 'distilbert.transformer.layer.0.ffn.lin1', 'distilbert.transformer.layer.0.ffn.lin2', 'distilbert.transformer.layer.1.attention.q_lin', 'distilbert.transformer.layer.1.attention.k_lin', 'distilbert.transformer.layer.1.attention.v_lin', 'distilbert.transformer.layer.1.attention.out_lin', 'distilbert.transformer.layer.1.ffn.lin1', 'distilbert.transformer.layer.1.ffn.lin2', 'distilbert.transformer.layer.2.attention.q_lin', 'distilbert.transformer.layer.2.attention.k_lin', 'distilbert.transformer.layer.2.attention.v_lin', 'distilbert.transformer.layer.2.attention.out_lin', 'distilbert.transformer.layer.2.ffn.lin1', 'distilbert.transformer.layer.2.ffn.lin2', 'distilbert.transformer.layer.3.attention.q_lin', 'distilbert.transformer.layer.3.attention.k_lin', 'distilbert.transformer.layer.3.attention.v_lin', 'distilbert.transformer.layer.3.attention.out_lin', 'distilbert.transformer.layer.3.ffn.lin1', 'distilbert.transformer.layer.3.ffn.lin2', 'distilbert.transformer.layer.4.attention.q_lin', 'distilbert.transformer.layer.4.attention.k_lin', 'distilbert.transformer.layer.4.attention.v_lin', 'distilbert.transformer.layer.4.attention.out_lin', 'distilbert.transformer.layer.4.ffn.lin1', 'distilbert.transformer.layer.4.ffn.lin2', 'distilbert.transformer.layer.5.attention.q_lin', 'distilbert.transformer.layer.5.attention.k_lin', 'distilbert.transformer.layer.5.attention.v_lin', 'distilbert.transformer.layer.5.attention.out_lin', 'distilbert.transformer.layer.5.ffn.lin1', 'distilbert.transformer.layer.5.ffn.lin2']\ntrainable params: 2,511,364 || all params: 68,874,244 || trainable%: 3.646303544181189\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:",
          "output_type": "stream"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "  ········································\n"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "wandb version 0.17.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.17.4"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20240730_151535-4z2z1yfw</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/benuehlinger2/huggingface/runs/4z2z1yfw' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/benuehlinger2/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/benuehlinger2/huggingface' target=\"_blank\">https://wandb.ai/benuehlinger2/huggingface</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/benuehlinger2/huggingface/runs/4z2z1yfw' target=\"_blank\">https://wandb.ai/benuehlinger2/huggingface/runs/4z2z1yfw</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='12630' max='12630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12630/12630 14:36, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.250700</td>\n      <td>0.283276</td>\n      <td>0.880734</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.267700</td>\n      <td>0.295353</td>\n      <td>0.883028</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.225600</td>\n      <td>0.289473</td>\n      <td>0.893349</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Evaluating after fine-tuning...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [55/55 00:01]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Results after fine-tuning: {'eval_loss': 0.2894730865955353, 'eval_accuracy': 0.893348623853211, 'eval_runtime': 1.3155, 'eval_samples_per_second': 662.888, 'eval_steps_per_second': 41.811, 'epoch': 3.0}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:875: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "adapter_model.safetensors:   0%|          | 0.00/7.69M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e99fa74517a49eaaccc24f10e664a9a"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "CommitInfo(commit_url='https://huggingface.co/Benuehlinger/my-peft-distilbert/commit/b4ecedd371a0cdda52445f9eacc6151cd1701f30', commit_message='Upload model', commit_description='', oid='b4ecedd371a0cdda52445f9eacc6151cd1701f30', pr_url=None, pr_revision=None, pr_num=None)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the base model, the full finetune model and the LoRA model on out-of-sample sentences.\n",
        "\n",
        "Note: 20 sentences of certain sentiment, 1 sentence of mixed sentiment, and 1 sentence of nonsense characters.\n",
        "\n"
      ],
      "metadata": {
        "id": "BTKt4nJRuZpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
        "from peft import PeftModel, PeftConfig\n",
        "import torch\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load the original, fine-tuned, and PEFT models\n",
        "original_model_name = \"distilbert-base-uncased\"\n",
        "fine_tuned_model_name = \"Benuehlinger/my-fine-tuned-distilbert\"\n",
        "peft_model_name = \"Benuehlinger/my-peft-distilbert\"  # Replace with your actual PEFT model name\n",
        "tokenizer = AutoTokenizer.from_pretrained(original_model_name)\n",
        "\n",
        "# Load models and move them to the appropriate device\n",
        "original_model = AutoModelForSequenceClassification.from_pretrained(original_model_name).to(device)\n",
        "fine_tuned_model = AutoModelForSequenceClassification.from_pretrained(fine_tuned_model_name).to(device)\n",
        "\n",
        "# Load the PEFT model\n",
        "peft_config = PeftConfig.from_pretrained(peft_model_name)\n",
        "peft_model = AutoModelForSequenceClassification.from_pretrained(peft_config.base_model_name_or_path).to(device)\n",
        "peft_model = PeftModel.from_pretrained(peft_model, peft_model_name).to(device)\n",
        "\n",
        "# Set up pipelines for sequence classification\n",
        "original_classifier = pipeline(\"text-classification\", model=original_model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
        "fine_tuned_classifier = pipeline(\"text-classification\", model=fine_tuned_model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
        "peft_classifier = pipeline(\"text-classification\", model=peft_model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
        "\n",
        "# Generate new sentences\n",
        "new_sentences = [\n",
        "    \"I love the new movie, it's fantastic!\",\n",
        "    \"This product is terrible, I regret buying it.\",\n",
        "    \"The weather today is amazing, perfect for a picnic!\",\n",
        "    \"I feel so happy and excited about the upcoming event.\",\n",
        "    \"The service at this restaurant was extremely slow and disappointing.\",\n",
        "    \"I am very satisfied with the quality of this product.\",\n",
        "    \"The performance of the team was outstanding in the match.\",\n",
        "    \"The book I read recently was very engaging and well-written.\",\n",
        "    \"I had a great experience shopping at this store.\",\n",
        "    \"The movie I watched last night was a complete waste of time.\",\n",
        "    \"The customer service at this company needs improvement.\",\n",
        "    \"The food at the restaurant was delicious and well-prepared.\",\n",
        "    \"I strongly recommend this product to everyone.\",\n",
        "    \"The hotel I stayed in during my vacation was luxurious and comfortable.\",\n",
        "    \"The new feature added to the app is very user-friendly.\",\n",
        "    \"The concert I attended last week was amazing!\",\n",
        "    \"I had a terrible experience with the customer support.\",\n",
        "    \"The new design of the website is sleek and modern.\",\n",
        "    \"The movie had a predictable plot and was not very entertaining.\",\n",
        "    \"The delivery of my order was delayed and caused inconvenience.\",\n",
        "    \"This Movie had a good plot but weak special effects.\",\n",
        "    \"xyzdoaskeqw\"\n",
        "]\n",
        "\n",
        "# Compare predictions between the original, fine-tuned, and PEFT models for each sentence\n",
        "for sentence in new_sentences:\n",
        "    # Get predictions from all models\n",
        "    original_prediction = original_classifier(sentence)[0]\n",
        "    fine_tuned_prediction = fine_tuned_classifier(sentence)[0]\n",
        "    peft_prediction = peft_classifier(sentence)[0]\n",
        "\n",
        "    # Print predictions\n",
        "    print(\"Sentence:\", sentence)\n",
        "    print(\"Original Model Prediction:\", original_prediction)\n",
        "    print(\"Fine-Tuned Model Prediction:\", fine_tuned_prediction)\n",
        "    print(\"PEFT Model Prediction:\", peft_prediction)\n",
        "    print()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-30T16:12:52.748309Z",
          "iopub.execute_input": "2024-07-30T16:12:52.748770Z",
          "iopub.status.idle": "2024-07-30T16:13:07.238724Z",
          "shell.execute_reply.started": "2024-07-30T16:12:52.748733Z",
          "shell.execute_reply": "2024-07-30T16:13:07.237495Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "b643490461204c67a4f5548e23511b48",
            "a288b6fc8f504b7a8008cbc5595ec008",
            "bef5d9bb7caa4960bc1c1737757f3ce0",
            "bcc792f8d0b041739b8552103b1cf3c1"
          ]
        },
        "id": "E_-HhPO6uZpT",
        "outputId": "7027f47d-4282-41c4-a8e6-e64ba7a0e0de"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Using device: cuda\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b643490461204c67a4f5548e23511b48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a288b6fc8f504b7a8008cbc5595ec008"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "adapter_config.json:   0%|          | 0.00/2.29k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bef5d9bb7caa4960bc1c1737757f3ce0"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "adapter_model.safetensors:   0%|          | 0.00/7.69M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcc792f8d0b041739b8552103b1cf3c1"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "The model 'PeftModelForSequenceClassification' is not supported for text-classification. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GemmaForSequenceClassification', 'Gemma2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'IBertForSequenceClassification', 'JambaForSequenceClassification', 'JetMoeForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'Phi3ForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'Qwen2ForSequenceClassification', 'Qwen2MoeForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'StableLmForSequenceClassification', 'Starcoder2ForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification'].\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Sentence: I love the new movie, it's fantastic!\nOriginal Model Prediction: {'label': 'LABEL_0', 'score': 0.5196182727813721}\nFine-Tuned Model Prediction: {'label': 'LABEL_1', 'score': 0.9996926784515381}\nPEFT Model Prediction: {'label': 'LABEL_1', 'score': 0.9993448853492737}\n\nSentence: This product is terrible, I regret buying it.\nOriginal Model Prediction: {'label': 'LABEL_0', 'score': 0.5233114361763}\nFine-Tuned Model Prediction: {'label': 'LABEL_0', 'score': 0.9982353448867798}\nPEFT Model Prediction: {'label': 'LABEL_0', 'score': 0.9869326949119568}\n\nSentence: The weather today is amazing, perfect for a picnic!\nOriginal Model Prediction: {'label': 'LABEL_0', 'score': 0.5181533098220825}\nFine-Tuned Model Prediction: {'label': 'LABEL_1', 'score': 0.9995694756507874}\nPEFT Model Prediction: {'label': 'LABEL_1', 'score': 0.9985925555229187}\n\nSentence: I feel so happy and excited about the upcoming event.\nOriginal Model Prediction: {'label': 'LABEL_0', 'score': 0.5294833183288574}\nFine-Tuned Model Prediction: {'label': 'LABEL_1', 'score': 0.9995142221450806}\nPEFT Model Prediction: {'label': 'LABEL_1', 'score': 0.9964836835861206}\n\nSentence: The service at this restaurant was extremely slow and disappointing.\nOriginal Model Prediction: {'label': 'LABEL_0', 'score': 0.5242716073989868}\nFine-Tuned Model Prediction: {'label': 'LABEL_0', 'score': 0.9987633228302002}\nPEFT Model Prediction: {'label': 'LABEL_0', 'score': 0.9968551397323608}\n\nSentence: I am very satisfied with the quality of this product.\nOriginal Model Prediction: {'label': 'LABEL_0', 'score': 0.5127538442611694}\nFine-Tuned Model Prediction: {'label': 'LABEL_1', 'score': 0.9966243505477905}\nPEFT Model Prediction: {'label': 'LABEL_1', 'score': 0.9873968958854675}\n\nSentence: The performance of the team was outstanding in the match.\nOriginal Model Prediction: {'label': 'LABEL_0', 'score': 0.5211519598960876}\nFine-Tuned Model Prediction: {'label': 'LABEL_1', 'score': 0.9996238946914673}\nPEFT Model Prediction: {'label': 'LABEL_1', 'score': 0.9974849224090576}\n\nSentence: The book I read recently was very engaging and well-written.\nOriginal Model Prediction: {'label': 'LABEL_0', 'score': 0.5232570171356201}\nFine-Tuned Model Prediction: {'label': 'LABEL_1', 'score': 0.9997102618217468}\nPEFT Model Prediction: {'label': 'LABEL_1', 'score': 0.9995118379592896}\n\nSentence: I had a great experience shopping at this store.\nOriginal Model Prediction: {'label': 'LABEL_0', 'score': 0.5285704731941223}\nFine-Tuned Model Prediction: {'label': 'LABEL_1', 'score': 0.9986575841903687}\nPEFT Model Prediction: {'label': 'LABEL_1', 'score': 0.9940318465232849}\n\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Sentence: The movie I watched last night was a complete waste of time.\nOriginal Model Prediction: {'label': 'LABEL_0', 'score': 0.5215651392936707}\nFine-Tuned Model Prediction: {'label': 'LABEL_0', 'score': 0.9990159273147583}\nPEFT Model Prediction: {'label': 'LABEL_0', 'score': 0.9972447156906128}\n\nSentence: The customer service at this company needs improvement.\nOriginal Model Prediction: {'label': 'LABEL_0', 'score': 0.5050338506698608}\nFine-Tuned Model Prediction: {'label': 'LABEL_0', 'score': 0.9972436428070068}\nPEFT Model Prediction: {'label': 'LABEL_0', 'score': 0.6307623386383057}\n\nSentence: The food at the restaurant was delicious and well-prepared.\nOriginal Model Prediction: {'label': 'LABEL_0', 'score': 0.5133419036865234}\nFine-Tuned Model Prediction: {'label': 'LABEL_1', 'score': 0.9996544122695923}\nPEFT Model Prediction: {'label': 'LABEL_1', 'score': 0.9976463913917542}\n\nSentence: I strongly recommend this product to everyone.\nOriginal Model Prediction: {'label': 'LABEL_0', 'score': 0.514382541179657}\nFine-Tuned Model Prediction: {'label': 'LABEL_1', 'score': 0.9994113445281982}\nPEFT Model Prediction: {'label': 'LABEL_1', 'score': 0.9401139616966248}\n\nSentence: The hotel I stayed in during my vacation was luxurious and comfortable.\nOriginal Model Prediction: {'label': 'LABEL_0', 'score': 0.5155490636825562}\nFine-Tuned Model Prediction: {'label': 'LABEL_1', 'score': 0.9994975328445435}\nPEFT Model Prediction: {'label': 'LABEL_1', 'score': 0.9983770847320557}\n\nSentence: The new feature added to the app is very user-friendly.\nOriginal Model Prediction: {'label': 'LABEL_0', 'score': 0.5170662999153137}\nFine-Tuned Model Prediction: {'label': 'LABEL_1', 'score': 0.9888491630554199}\nPEFT Model Prediction: {'label': 'LABEL_1', 'score': 0.9908081889152527}\n\nSentence: The concert I attended last week was amazing!\nOriginal Model Prediction: {'label': 'LABEL_0', 'score': 0.5264846086502075}\nFine-Tuned Model Prediction: {'label': 'LABEL_1', 'score': 0.9995558857917786}\nPEFT Model Prediction: {'label': 'LABEL_1', 'score': 0.998781144618988}\n\nSentence: I had a terrible experience with the customer support.\nOriginal Model Prediction: {'label': 'LABEL_0', 'score': 0.5284839272499084}\nFine-Tuned Model Prediction: {'label': 'LABEL_0', 'score': 0.9970923662185669}\nPEFT Model Prediction: {'label': 'LABEL_0', 'score': 0.9906895160675049}\n\nSentence: The new design of the website is sleek and modern.\nOriginal Model Prediction: {'label': 'LABEL_0', 'score': 0.5228025913238525}\nFine-Tuned Model Prediction: {'label': 'LABEL_1', 'score': 0.9994643330574036}\nPEFT Model Prediction: {'label': 'LABEL_1', 'score': 0.9957915544509888}\n\nSentence: The movie had a predictable plot and was not very entertaining.\nOriginal Model Prediction: {'label': 'LABEL_0', 'score': 0.5267935395240784}\nFine-Tuned Model Prediction: {'label': 'LABEL_0', 'score': 0.9988340735435486}\nPEFT Model Prediction: {'label': 'LABEL_0', 'score': 0.9970791339874268}\n\nSentence: The delivery of my order was delayed and caused inconvenience.\nOriginal Model Prediction: {'label': 'LABEL_0', 'score': 0.517270565032959}\nFine-Tuned Model Prediction: {'label': 'LABEL_0', 'score': 0.998353123664856}\nPEFT Model Prediction: {'label': 'LABEL_0', 'score': 0.9927120208740234}\n\nSentence: This Movie had a good plot but weak special effects.\nOriginal Model Prediction: {'label': 'LABEL_0', 'score': 0.5239971280097961}\nFine-Tuned Model Prediction: {'label': 'LABEL_0', 'score': 0.995608389377594}\nPEFT Model Prediction: {'label': 'LABEL_0', 'score': 0.9790946841239929}\n\nSentence: xyzdoaskeqw\nOriginal Model Prediction: {'label': 'LABEL_0', 'score': 0.5439310669898987}\nFine-Tuned Model Prediction: {'label': 'LABEL_1', 'score': 0.5449567437171936}\nPEFT Model Prediction: {'label': 'LABEL_0', 'score': 0.675632655620575}\n\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}